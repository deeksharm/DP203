getting scope from databricks
dbutils.secrets.listScopes()
adlskey = dbutils.secrets.get(scope=<scope-name>, key=<secret name>)
spark.conf.set('fs.azure.account.key.adlsdemo2025training.dfs.core.windows.net', adlskey)
